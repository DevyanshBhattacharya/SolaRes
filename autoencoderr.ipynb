{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6245bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cfe46cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentations\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Radial vignetting / limb-darkening perturbation\n",
    "# ----------------------------\n",
    "def radial_vignette(img, strength=0.2):\n",
    "    \"\"\"\n",
    "    Apply radial vignette (simulate limb-darkening).\n",
    "    strength: 0.0 (none) to 0.5 (strong)\n",
    "    \"\"\"\n",
    "    h, w = img.shape\n",
    "    y, x = np.ogrid[:h, :w]\n",
    "    cy, cx = h / 2, w / 2\n",
    "    r = np.sqrt((x - cx)**2 + (y - cy)**2)\n",
    "    r = r / r.max()  # normalize radius [0,1]\n",
    "    \n",
    "    # limb-darkening multiplier\n",
    "    mask = 1 - strength * (r**2)  \n",
    "    vignette = img.astype(np.float32) * mask\n",
    "    vignette = np.clip(vignette, 0, 255)\n",
    "    return vignette.astype(np.uint8)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Poisson noise (photon noise)\n",
    "# ----------------------------\n",
    "def add_poisson_noise(img, scale_low=5.0, scale_high=100.0):\n",
    "    \"\"\"\n",
    "    Add Poisson noise to simulate photon noise.\n",
    "    \"\"\"\n",
    "    if img.dtype != np.float32:\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "    scale = random.uniform(scale_low, scale_high)\n",
    "    noisy = np.random.poisson(img * scale) / float(scale)\n",
    "    noisy = np.clip(noisy, 0.0, 1.0)\n",
    "    return (noisy * 255).astype(np.uint8)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Small rotations\n",
    "# ----------------------------\n",
    "def random_rotation(img, angle_range=20):\n",
    "    \"\"\"\n",
    "    Rotate image by random angle within ±angle_range.\n",
    "    \"\"\"\n",
    "    h, w = img.shape\n",
    "    angle = random.uniform(-angle_range, angle_range)\n",
    "    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "    rotated = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "    return rotated\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Random crop + resize\n",
    "# ----------------------------\n",
    "def random_crop_resize(img, crop_scale=0.8, out_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Random crop followed by resize.\n",
    "    crop_scale: fraction of original image kept (0.5–1.0).\n",
    "    \"\"\"\n",
    "    h, w = img.shape\n",
    "    ch, cw = int(h * crop_scale), int(w * crop_scale)\n",
    "    y = random.randint(0, h - ch)\n",
    "    x = random.randint(0, w - cw)\n",
    "    crop = img[y:y+ch, x:x+cw]\n",
    "    resized = cv2.resize(crop, out_size, interpolation=cv2.INTER_LINEAR)\n",
    "    return resized\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Gaussian blur (PSF-like)\n",
    "# ----------------------------\n",
    "def gaussian_blur(img, sigma_range=(0.5, 2.0)):\n",
    "    \"\"\"\n",
    "    Apply Gaussian blur with random sigma.\n",
    "    \"\"\"\n",
    "    sigma = random.uniform(*sigma_range)\n",
    "    ksize = int(2 * round(3*sigma) + 1)  # kernel size ~ 6*sigma\n",
    "    blurred = cv2.GaussianBlur(img, (ksize, ksize), sigmaX=sigma)\n",
    "    return blurred\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Brightness/contrast jitter\n",
    "# ----------------------------\n",
    "def brightness_contrast_jitter(img, brightness=0.2, contrast=0.3):\n",
    "    \"\"\"\n",
    "    Random brightness/contrast adjustment.\n",
    "    brightness: fraction (e.g. 0.2 → ±20%)\n",
    "    contrast: fraction (e.g. 0.3 → ±30%)\n",
    "    \"\"\"\n",
    "    b = random.uniform(-brightness, brightness) * 255\n",
    "    c = 1.0 + random.uniform(-contrast, contrast)\n",
    "    jittered = img.astype(np.float32) * c + b\n",
    "    jittered = np.clip(jittered, 0, 255)\n",
    "    return jittered.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd4108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)  # latent: [B,64,H/8,W/8]\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64,32,3,stride=2,padding=1,output_padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32,16,3,stride=2,padding=1,output_padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16,1,3,stride=2,padding=1,output_padding=1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.deconv(x)\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)    # compress to latent vector\n",
    "        reconstructed = self.decoder(latent)  # reconstruct image\n",
    "        return reconstructed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d12729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class SolarDataset(Dataset):\n",
    "    def __init__(self, lr_dir, hr_dir, augment=True, img_size=(256,256),max_images=None):\n",
    "        self.lr_files = sorted([os.path.join(lr_dir, f) for f in os.listdir(lr_dir)])\n",
    "        self.hr_files = sorted([os.path.join(hr_dir, f) for f in os.listdir(hr_dir)])\n",
    "        if max_images is not None:\n",
    "            self.lr_files = self.lr_files[:max_images]\n",
    "            self.hr_files = self.hr_files[:max_images]\n",
    "        self.augment = augment\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load images\n",
    "        lr = cv2.imread(self.lr_files[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        hr = cv2.imread(self.hr_files[idx], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Resize to same size\n",
    "        lr = cv2.resize(lr, self.img_size)\n",
    "        hr = cv2.resize(hr, self.img_size)\n",
    "\n",
    "        # Apply augmentations to LR only\n",
    "        if self.augment:\n",
    "            lr = radial_vignette(lr, strength=random.uniform(0.05,0.2))\n",
    "            lr = add_poisson_noise(lr)\n",
    "            lr = random_rotation(lr, angle_range=15)\n",
    "            lr = gaussian_blur(lr, sigma_range=(0.5,1.5))\n",
    "            lr = brightness_contrast_jitter(lr, brightness=0.15, contrast=0.2)\n",
    "        \n",
    "        # Normalize and convert to tensor [C,H,W]\n",
    "        lr = torch.tensor(lr, dtype=torch.float32).unsqueeze(0)/255.0\n",
    "        hr = torch.tensor(hr, dtype=torch.float32).unsqueeze(0)/255.0\n",
    "\n",
    "        return lr, hr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83b55fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "max_images = 1000\n",
    "\n",
    "train_dataset = SolarDataset(\"new_dataset/training/low_res\", \n",
    "                             \"new_dataset/training/high_res\", \n",
    "                             augment=True, max_images=max_images)\n",
    "\n",
    "val_dataset = SolarDataset(\"new_dataset/validation/low_res\", \n",
    "                           \"new_dataset/validation/high_res\", \n",
    "                           augment=False, max_images=max_images)\n",
    "\n",
    "test_dataset = SolarDataset(\"new_dataset/testing/low_res\", \n",
    "                            \"new_dataset/testing/high_res\", \n",
    "                            augment=False, max_images=max_images)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torchmetrics.functional import structural_similarity_index_measure as ssim\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics\n",
    "# -----------------------------\n",
    "def pixelwise_error(pred, target):\n",
    "    return torch.mean(torch.abs(pred - target)).item()\n",
    "\n",
    "def psnr(pred, target, max_val=1.0):\n",
    "    mse = torch.mean((pred - target) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * torch.log10(max_val / torch.sqrt(mse)).item()\n",
    "\n",
    "\n",
    "def ssim_metric(pred, target):\n",
    "    return ssim(pred, target, data_range=1.0).item()  \n",
    "\n",
    "# -----------------------------\n",
    "# Hyperparameters\n",
    "# -----------------------------\n",
    "batch_size = 8\n",
    "lr = 1e-3\n",
    "epochs = 20\n",
    "latent_dim = 128\n",
    "\n",
    "# -----------------------------\n",
    "# Model, Loss, Optimizer\n",
    "# -----------------------------\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# -----------------------------\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "bottleneck_embeddings = []\n",
    "\n",
    "# -----------------------------\n",
    "# Training Loop\n",
    "# -----------------------------\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for lr_imgs, hr_imgs in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\"):\n",
    "        lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(lr_imgs)\n",
    "        loss = criterion(outputs, hr_imgs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * lr_imgs.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    pixel_err = 0\n",
    "    psnr_val = 0\n",
    "    ssim_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for lr_imgs, hr_imgs in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n",
    "            lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "\n",
    "            outputs = model(lr_imgs)\n",
    "            loss = criterion(outputs, hr_imgs)\n",
    "            val_loss += loss.item() * lr_imgs.size(0)\n",
    "\n",
    "            pixel_err += pixelwise_error(outputs, hr_imgs) * lr_imgs.size(0)\n",
    "            psnr_val += psnr(outputs, hr_imgs) * lr_imgs.size(0)\n",
    "            ssim_val += ssim_metric(outputs, hr_imgs) * lr_imgs.size(0)\n",
    "\n",
    "            # Save bottleneck embeddings\n",
    "            latent = model.encoder(lr_imgs)\n",
    "            bottleneck_embeddings.append(latent.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    pixel_err /= len(val_loader.dataset)\n",
    "    psnr_val /= len(val_loader.dataset)\n",
    "    ssim_val /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.6f} | \"\n",
    "          f\"Val Loss: {val_loss:.6f} | \"\n",
    "          f\"Pixel Error: {pixel_err:.6f} | \"\n",
    "          f\"PSNR: {psnr_val:.2f} dB | \"\n",
    "          f\"SSIM: {ssim_val:.4f}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save checkpoints\n",
    "    # -----------------------------\n",
    "    torch.save(model.state_dict(), os.path.join(checkpoint_dir, f\"autoencoder_epoch{epoch+1}.pth\"))\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), os.path.join(checkpoint_dir, \"best_autoencoder.pth\"))\n",
    "        print(f\"Best model updated at epoch {epoch+1}\")\n",
    "\n",
    "# Save bottleneck embeddings\n",
    "bottleneck_embeddings = np.concatenate(bottleneck_embeddings, axis=0)\n",
    "np.save(\"bottleneck_embeddings.npy\", bottleneck_embeddings)\n",
    "print(\"Bottleneck embeddings saved:\", bottleneck_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.functional import structural_similarity_index_measure as ssim\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics\n",
    "# -----------------------------\n",
    "def pixelwise_error(pred, target):\n",
    "    return torch.mean(torch.abs(pred - target)).item()\n",
    "\n",
    "def psnr(pred, target, max_val=1.0):\n",
    "    mse = torch.mean((pred - target) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * torch.log10(max_val / torch.sqrt(mse)).item()\n",
    "\n",
    "def ssim_metric(pred, target):\n",
    "    return ssim(pred, target, data_range=1.0).item()\n",
    "\n",
    "# -----------------------------\n",
    "# Load model\n",
    "# -----------------------------\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Autoencoder().to(device)\n",
    "model.load_state_dict(torch.load(\"checkpoints/best_autoencoder.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Directory to save reconstructed images\n",
    "os.makedirs(\"reconstructed_images\", exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Testing and Visualization\n",
    "# -----------------------------\n",
    "psnr_list = []\n",
    "ssim_list = []\n",
    "pixel_err_list = []\n",
    "\n",
    "count = 0  # to limit visualization\n",
    "for lr_imgs, hr_imgs in tqdm(test_loader, desc=\"Testing\"):\n",
    "    lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(lr_imgs)\n",
    "    \n",
    "    for i in range(lr_imgs.size(0)):\n",
    "    # Move to CPU and convert to float\n",
    "        pred_img = outputs[i].detach().cpu().float()\n",
    "        true_img = hr_imgs[i].detach().cpu().float()\n",
    "\n",
    "    # Add channel dimension for SSIM: [1, 1, H, W]\n",
    "        pred_img_ssim = pred_img.unsqueeze(0)  # shape: [1, 1, H, W]\n",
    "        true_img_ssim = true_img.unsqueeze(0)  # shape: [1, 1, H, W]\n",
    "\n",
    "    # Metrics\n",
    "        psnr_list.append(psnr(pred_img, true_img))\n",
    "        ssim_list.append(ssim_metric(pred_img_ssim, true_img_ssim))\n",
    "        pixel_err_list.append(pixelwise_error(pred_img, true_img))\n",
    "        \n",
    "        # Save reconstructed image\n",
    "        recon_img_path = f\"reconstructed_images/recon_{count}.png\"\n",
    "        plt.imsave(recon_img_path, pred_img.squeeze(), cmap='gray')\n",
    "        \n",
    "        # Display side by side for first 5 images\n",
    "        if count < 5:\n",
    "            fig, axes = plt.subplots(1,2, figsize=(6,3))\n",
    "            axes[0].imshow(true_img.squeeze(), cmap='gray')\n",
    "            axes[0].set_title(\"Original\")\n",
    "            axes[0].axis('off')\n",
    "            axes[1].imshow(pred_img.squeeze(), cmap='gray')\n",
    "            axes[1].set_title(\"Reconstructed\")\n",
    "            axes[1].axis('off')\n",
    "            plt.show()\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "\n",
    "print(f\"Average PSNR: {np.mean(psnr_list):.2f} dB\")\n",
    "print(f\"Average SSIM: {np.mean(ssim_list):.4f}\")\n",
    "print(f\"Average Pixel Error: {np.mean(pixel_err_list):.6f}\")\n",
    "print(f\"Reconstructed images saved in 'reconstructed_images/' folder\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
