{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc2e69a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4789964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "Built on Sat_Aug_25_21:08:04_Central_Daylight_Time_2018\n",
      "Cuda compilation tools, release 10.0, V10.0.130\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a04eafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"Memory growth set for GPU:\", gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13f16bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPU\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbf92097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class PixelShuffle(Layer):\n",
    "    def __init__(self, scale, **kwargs):\n",
    "        super(PixelShuffle, self).__init__(**kwargs)\n",
    "        self.scale = scale\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.nn.depth_to_space(x, self.scale)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PixelShuffle, self).get_config()\n",
    "        config.update({\"scale\": self.scale})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d597f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "# ---------------------------\n",
    "# Mixed precision for speed\n",
    "# ---------------------------\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# ---------------------------\n",
    "# Residual Block\n",
    "# ---------------------------\n",
    "def ResidualBlock(x_input, filters=64, kernel_size=3):\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.PReLU(shared_axes=[1,2])(x)\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x_input, x])\n",
    "    return x\n",
    "\n",
    "# ---------------------------\n",
    "# Generator\n",
    "# ---------------------------\n",
    "def build_generator(num_res_blocks=16, upscaling_factor=4):\n",
    "    inputs = layers.Input(shape=(None, None, 3))\n",
    "    x = layers.Conv2D(64, 9, padding='same')(inputs)\n",
    "    x_ = layers.PReLU(shared_axes=[1,2])(x)\n",
    "    \n",
    "    x_res = x_\n",
    "    for _ in range(num_res_blocks):\n",
    "        x_res = ResidualBlock(x_res, 64)\n",
    "    \n",
    "    x = layers.Conv2D(64, 3, padding='same')(x_res)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x_, x])\n",
    "    \n",
    "    num_upsample = int(math.log2(upscaling_factor))\n",
    "    x_up = x\n",
    "    for _ in range(num_upsample):\n",
    "        x_up = layers.Conv2D(256, 3, padding='same')(x_up)\n",
    "        x_up = PixelShuffle(2)(x_up)\n",
    "        x_up = layers.PReLU(shared_axes=[1,2])(x_up)\n",
    "    \n",
    "    outputs = layers.Conv2D(3, 9, padding='same', activation='tanh')(x_up)\n",
    "    return Model(inputs, outputs, name='Generator')\n",
    "\n",
    "# ---------------------------\n",
    "# Discriminator\n",
    "# ---------------------------\n",
    "def build_discriminator(input_shape=(None, None, 3)):\n",
    "    def disc_block(x, filters, stride):\n",
    "        x = layers.Conv2D(filters, 3, strides=stride, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        return x\n",
    "    \n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, 3, strides=1, padding='same')(inputs)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = disc_block(x, 64, 2)\n",
    "    x = disc_block(x, 128, 1)\n",
    "    x = disc_block(x, 128, 2)\n",
    "    x = disc_block(x, 256, 1)\n",
    "    x = disc_block(x, 256, 2)\n",
    "    x = disc_block(x, 512, 1)\n",
    "    x = disc_block(x, 512, 2)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D()(x)    \n",
    "    x = layers.Dense(1024)(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    outputs = layers.Dense(1)(x)  # logits\n",
    "    return Model(inputs, outputs, name='Discriminator')\n",
    "\n",
    "# ---------------------------\n",
    "# VGG19 feature extractor\n",
    "# ---------------------------\n",
    "def build_vgg19_feature_extractor():\n",
    "    vgg = VGG19(weights='imagenet', include_top=False, input_shape=(None, None, 3))\n",
    "    model = Model(inputs=vgg.input, outputs=vgg.get_layer('block5_conv4').output)\n",
    "    model.trainable = False\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d822b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.image import psnr, ssim\n",
    "from tqdm import tqdm \n",
    "\n",
    "# ---------------------------\n",
    "# IMAGE UTILITIES\n",
    "# ---------------------------\n",
    "def load_image(path):\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    return np.array(img)\n",
    "\n",
    "def preprocess(img):\n",
    "    img = img / 127.5 - 1.0  # scale [-1,1]\n",
    "    return img.astype(np.float32)\n",
    "\n",
    "def deprocess(img):\n",
    "    img = ((img + 1.0) * 127.5).clip(0,255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def make_pairs(lr_dir, hr_dir):\n",
    "    lr_files = sorted(glob.glob(os.path.join(lr_dir, '*')))\n",
    "    pairs = []\n",
    "    for lr_path in lr_files:\n",
    "        hr_path = os.path.join(hr_dir, os.path.basename(lr_path))\n",
    "        if os.path.exists(hr_path):\n",
    "            pairs.append((lr_path, hr_path))\n",
    "    return pairs\n",
    "\n",
    "# ---------------------------\n",
    "# DATASET LOADER\n",
    "# ---------------------------\n",
    "def dataset_from_pairs(pairs, batch_size):\n",
    "    if len(pairs) == 0:\n",
    "        raise ValueError(\"No image pairs found!\")\n",
    "\n",
    "    def generator():\n",
    "        for lr_path, hr_path in pairs:\n",
    "            lr = preprocess(load_image(lr_path))\n",
    "            hr = preprocess(load_image(hr_path))\n",
    "            yield lr, hr\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, None, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, None, 3), dtype=tf.float32),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    dataset = dataset.shuffle(buffer_size=max(1, len(pairs))) \\\n",
    "                     .batch(batch_size) \\\n",
    "                     .prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# ---------------------------\n",
    "# LOSSES\n",
    "# ---------------------------\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "mae = tf.keras.losses.MeanAbsoluteError()\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def content_loss(hr, sr):\n",
    "    return mae(hr, sr)\n",
    "\n",
    "def adversarial_loss(real_logits, fake_logits):\n",
    "    d_loss = bce(tf.ones_like(real_logits), real_logits) + \\\n",
    "             bce(tf.zeros_like(fake_logits), fake_logits)\n",
    "    g_loss = bce(tf.ones_like(fake_logits), fake_logits)\n",
    "    return g_loss, d_loss\n",
    "\n",
    "def perceptual_loss(vgg, hr, sr):\n",
    "    hr_vgg = (hr + 1.0) * 127.5\n",
    "    sr_vgg = (sr + 1.0) * 127.5\n",
    "    hr_feat = vgg(hr_vgg)\n",
    "    sr_feat = vgg(sr_vgg)\n",
    "    return mse(hr_feat, sr_feat)\n",
    "\n",
    "# ---------------------------\n",
    "# TRAINING LOOP\n",
    "# ---------------------------\n",
    "def train(\n",
    "    train_lr_dir='C:\\\\Users\\\\bhatt\\\\Machine Learning\\\\SolaRess\\\\new_dataset\\\\training\\\\low_res',\n",
    "    train_hr_dir='C:\\\\Users\\\\bhatt\\\\Machine Learning\\\\SolaRess\\\\new_dataset\\\\training\\\\high_res',\n",
    "    val_lr_dir='C:\\\\Users\\\\bhatt\\\\Machine Learning\\\\SolaRess\\\\new_dataset\\\\validation\\\\low_res',\n",
    "    val_hr_dir='C:\\\\Users\\\\bhatt\\\\Machine Learning\\\\SolaRess\\\\new_dataset\\\\validation\\\\high_res',\n",
    "    epochs=1,\n",
    "    batch_size=2,\n",
    "    lr_g=1e-4,\n",
    "    lr_d=1e-4,\n",
    "    checkpoint_dir='checkpoints',\n",
    "    sample_dir='samples',\n",
    "    upscaling_factor=4\n",
    "):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "    # Build models\n",
    "    G = build_generator(upscaling_factor=upscaling_factor)\n",
    "    D = build_discriminator()\n",
    "    VGG = build_vgg19_feature_extractor()\n",
    "\n",
    "    # Optimizers\n",
    "    opt_g = tf.keras.optimizers.Adam(lr_g, beta_1=0.9)\n",
    "    opt_d = tf.keras.optimizers.Adam(lr_d, beta_1=0.9)\n",
    "\n",
    "    # Load dataset\n",
    "    train_pairs = make_pairs(train_lr_dir, train_hr_dir)\n",
    "    val_pairs = make_pairs(val_lr_dir, val_hr_dir)\n",
    "    train_dataset = dataset_from_pairs(train_pairs, batch_size)\n",
    "\n",
    "    steps_per_epoch = len(train_pairs) // batch_size\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        start_time = time.time()\n",
    "        running_g_loss = 0.0\n",
    "        running_d_loss = 0.0\n",
    "\n",
    "        # Training progress bar\n",
    "        train_iter = tqdm(train_dataset, desc=f\"Epoch {epoch}/{epochs} [Training]\", unit=\"batch\")\n",
    "        for lr_batch, hr_batch in train_iter:\n",
    "            # Train Discriminator\n",
    "            with tf.GradientTape() as tape_d:\n",
    "                sr_batch = G(lr_batch, training=True)\n",
    "                real_logits = D(hr_batch, training=True)\n",
    "                fake_logits = D(sr_batch, training=True)\n",
    "                g_adv, d_loss_val = adversarial_loss(real_logits, fake_logits)\n",
    "\n",
    "            grads_d = tape_d.gradient(d_loss_val, D.trainable_variables)\n",
    "            opt_d.apply_gradients(zip(grads_d, D.trainable_variables))\n",
    "\n",
    "            # Train Generator\n",
    "            with tf.GradientTape() as tape_g:\n",
    "                sr_batch = G(lr_batch, training=True)\n",
    "                fake_logits = D(sr_batch, training=True)\n",
    "                pixel_loss = content_loss(hr_batch, sr_batch)\n",
    "                perc_loss = perceptual_loss(VGG, hr_batch, sr_batch)\n",
    "                adv_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(\n",
    "                    tf.ones_like(fake_logits), fake_logits\n",
    "                )\n",
    "                g_loss_val = pixel_loss + 1e-2*perc_loss + 1e-3*adv_loss\n",
    "\n",
    "            grads_g = tape_g.gradient(g_loss_val, G.trainable_variables)\n",
    "            opt_g.apply_gradients(zip(grads_g, G.trainable_variables))\n",
    "\n",
    "            # Update running losses\n",
    "            running_g_loss += g_loss_val.numpy()\n",
    "            running_d_loss += d_loss_val.numpy()\n",
    "\n",
    "            # Update tqdm postfix\n",
    "            train_iter.set_postfix({\n",
    "                \"G_loss\": running_g_loss/(train_iter.n+1),\n",
    "                \"D_loss\": running_d_loss/(train_iter.n+1)\n",
    "            })\n",
    "\n",
    "        # Validation progress bar (small sample)\n",
    "        val_iter = tqdm(val_pairs[:10], desc=f\"Epoch {epoch}/{epochs} [Validation]\", unit=\"img\")\n",
    "        psnr_list, ssim_list = [], []\n",
    "        for i, (lr_path, hr_path) in enumerate(val_iter):\n",
    "            lr_img = preprocess(load_image(lr_path))[np.newaxis, ...]\n",
    "            hr_img = load_image(hr_path)\n",
    "            sr_img = G(lr_img, training=False).numpy()[0]\n",
    "            sr_img_np = deprocess(sr_img)\n",
    "\n",
    "            if sr_img_np.shape != hr_img.shape:\n",
    "                sr_img_np = np.array(\n",
    "                    Image.fromarray(sr_img_np).resize((hr_img.shape[1], hr_img.shape[0]), Image.BICUBIC)\n",
    "                )\n",
    "\n",
    "            psnr_list.append(tf.image.psnr(sr_img_np, hr_img, max_val=255).numpy())\n",
    "            ssim_list.append(tf.image.ssim(sr_img_np, hr_img, max_val=255).numpy())\n",
    "\n",
    "            # Save first 3 validation samples\n",
    "            if i < 3:\n",
    "                Image.fromarray(sr_img_np).save(os.path.join(sample_dir, f'epoch{epoch}_sample{i}.png'))\n",
    "\n",
    "            val_iter.set_postfix({\n",
    "                \"PSNR\": np.mean(psnr_list),\n",
    "                \"SSIM\": np.mean(ssim_list)\n",
    "            })\n",
    "\n",
    "        # Epoch summary\n",
    "        print(f\"\\nEpoch {epoch} complete! Time: {time.time()-start_time:.1f}s | \"\n",
    "            f\"Train G_loss={running_g_loss/len(train_dataset):.4f}, \"\n",
    "            f\"D_loss={running_d_loss/len(train_dataset):.4f} | \"\n",
    "            f\"Validation PSNR={np.mean(psnr_list):.2f}, SSIM={np.mean(ssim_list):.4f}\")\n",
    "\n",
    "        # Save checkpoints\n",
    "        G.save(os.path.join(checkpoint_dir, f'G_epoch{epoch}.h5'))\n",
    "        D.save(os.path.join(checkpoint_dir, f'D_epoch{epoch}.h5'))\n",
    "\n",
    "    print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792bffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 [Training]: 0batch [00:00, ?batch/s]"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
